{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Yacht Resistance with Linear Regression\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is a simple demonstration of how to use scikit-learn to build a Linear Regression model for regression. It uses a dataset of 308 experiments and their various attributes. The goal is to predict the residuary resistance per unit weight of displacement based upon the attributes.\n",
    "\n",
    "## The Data\n",
    "\n",
    "The data has been taken from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml) and the raw data and information can be found [here](https://archive.ics.uci.edu/ml/datasets/Yacht+Hydrodynamics). \n",
    "\n",
    "The columns are as follow:\n",
    "\n",
    "1. Longitudinal position of the center of buoyancy, adimensional.\n",
    "2. Prismatic coefficient, adimensional.\n",
    "3. Length-displacement ratio, adimensional.\n",
    "4. Beam-draught ratio, adimensional.\n",
    "5. Length-beam ratio, adimensional.\n",
    "6. Froude number, adimensional.\n",
    "7. Residuary resistance per unit weight of displacement, adimensional. \n",
    "\n",
    "Where column 7 is the target variable we are looking to predict.\n",
    "\n",
    "We import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the data we've saved, passing the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yacht = pd.read_csv(\"../c3o-experiments-main/kmeans.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the first few rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_count</th>\n",
       "      <th>machine_type</th>\n",
       "      <th>slots</th>\n",
       "      <th>memory</th>\n",
       "      <th>data_size_MB</th>\n",
       "      <th>features</th>\n",
       "      <th>observations</th>\n",
       "      <th>k</th>\n",
       "      <th>gross_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instance_count machine_type  slots  memory  data_size_MB  features   \n",
       "0               2   m4.2xlarge     16   64000          8000         5  \\\n",
       "1               2   m4.2xlarge     16   64000          8000         5   \n",
       "2               2   m4.2xlarge     16   64000          8000         5   \n",
       "3               2   m4.2xlarge     16   64000          8000         5   \n",
       "4               2   m4.2xlarge     16   64000          8000         5   \n",
       "\n",
       "   observations  k  gross_runtime  \n",
       "0     150000000  3           1126  \n",
       "1     150000000  3           1127  \n",
       "2     150000000  3           1151  \n",
       "3     150000000  3           1156  \n",
       "4     150000000  3           1216  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yacht.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly check if we have any null values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yacht.isnull().values.any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do! Let's use the \"describe\" method to find them, amongst other interesting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_count</th>\n",
       "      <th>slots</th>\n",
       "      <th>memory</th>\n",
       "      <th>data_size_MB</th>\n",
       "      <th>features</th>\n",
       "      <th>observations</th>\n",
       "      <th>k</th>\n",
       "      <th>gross_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>55.066667</td>\n",
       "      <td>413116.666667</td>\n",
       "      <td>18408.888889</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.366667e+08</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>533.698889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.417549</td>\n",
       "      <td>27.460883</td>\n",
       "      <td>209825.534684</td>\n",
       "      <td>5900.465554</td>\n",
       "      <td>3.561005</td>\n",
       "      <td>3.638259e+07</td>\n",
       "      <td>2.287462</td>\n",
       "      <td>791.443029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>61000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>244000.000000</td>\n",
       "      <td>13200.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>366000.000000</td>\n",
       "      <td>18600.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.250000e+08</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>610000.000000</td>\n",
       "      <td>21300.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.750000e+08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>434.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>732000.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000e+08</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4556.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instance_count       slots         memory  data_size_MB    features   \n",
       "count      900.000000  900.000000     900.000000    900.000000  900.000000  \\\n",
       "mean         7.000000   55.066667  413116.666667  18408.888889    7.000000   \n",
       "std          3.417549   27.460883  209825.534684   5900.465554    3.561005   \n",
       "min          2.000000    8.000000   61000.000000   8000.000000    5.000000   \n",
       "25%          4.000000   32.000000  244000.000000  13200.000000    5.000000   \n",
       "50%          7.000000   48.000000  366000.000000  18600.000000    5.000000   \n",
       "75%         10.000000   80.000000  610000.000000  21300.000000   10.000000   \n",
       "max         12.000000   96.000000  732000.000000  30500.000000   15.000000   \n",
       "\n",
       "       observations           k  gross_runtime  \n",
       "count  9.000000e+02  900.000000     900.000000  \n",
       "mean   1.366667e+08    5.800000     533.698889  \n",
       "std    3.638259e+07    2.287462     791.443029  \n",
       "min    1.000000e+08    3.000000      94.000000  \n",
       "25%    1.000000e+08    3.000000     182.000000  \n",
       "50%    1.250000e+08    5.000000     246.000000  \n",
       "75%    1.750000e+08    7.000000     434.500000  \n",
       "max    2.000000e+08    9.000000    4556.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yacht.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... the column *presmatic_coef* has 56 missing values... we can deal with this in a few different ways. The simpliest solution is to remove them, though we lose many examples in doing so. Alternatively, we could impute the values, replacing the NaN values with an average (mean or median). For the purpose of this simple notebook, we will simply remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yacht = yacht.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test Data\n",
    "\n",
    "The purpose of splitting the data is to be able to assess the quality of a predictive model when it is used on unseen data. When training, you will try to build a model that fits to the data as closely as possible, to be able to most accurately make a prediction. However, without a test set you run the risk of overfitting - the model works very well for the data it has seen but not for new data.\n",
    "\n",
    "The split ratio is often debated and in practice you might split your data into three sets: train, validation and test. You would use the training data to understand which classifier you wish to use; the validation set to test on whilst tweaking parameters; and the test set to get an understanding of how your final model would work in practice. Furthermore, there are techniques such as K-Fold cross validation that also help to reduce bias.\n",
    "\n",
    "For the purpose of this demonstration, we will only be randomly splitting our data into test and train, with a 80/20 split.\n",
    "\n",
    "We import the required library from scikit-learn, [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish for all features to be used for training, therefore we are taking all columns except \"class\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yacht.drop([\"gross_runtime\",\"machine_type\" ], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"class\" is our target variable, we set y as this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = yacht[\"gross_runtime\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the *train_test_split* function to create the appropriate train and test data for our features (\"X_train\" and \"X_test\" respectively) and target data (\"Y_train\" and \"Y_test\"). We are specifying our test data to be 20% of the total data. We are also providing a seed to be able to reproduce this split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of examples we have in each of our train and test data sets using \"shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation\n",
    "\n",
    "All features are numeric so we do not need to worry about converting categorical data with techniques such as one-hot encoding. However, we will demonstrate how to standardise our data. Standardisation rescales our attributes so they have a mean of 0 and standard deviation of 1. It assumes that the distribution is Gaussian (it works better if it is), alternatively normalisation can be used to rescale between the range of 0 and 1\n",
    "\n",
    "We use scikit-learn's [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the scaler, leaving parameters as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the scaler passing the training data but also request it transforms the data and returns it to a variable named \"train_scaled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform our test data with the same fitted scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear regression attempts to fit a straight hyperplane to your dataset that is closest to all data points. It is most suitable when there are linear relationships between the variables in the dataset.\n",
    "\n",
    "We are using scikit-learn's [Linear Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train it with our scaled training data and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_scaled, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We wish to understand how good our model is; there are a few different metrics we can use. We will evaluate mean squared error (MSE) and mean absolute error (MAE)\n",
    "\n",
    "We import [scikit-learn's mean squared error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error) and [sckit-learn's mean absolute error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the errors for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_train, model.predict(train_scaled))\n",
    "mae = mean_absolute_error(y_train, model.predict(train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse =  387067.79286411323  & mae =  410.03726598324056  & rmse =  622.1477259173365\n"
     ]
    }
   ],
   "source": [
    "print(\"mse = \",mse,\" & mae = \",mae,\" & rmse = \", sqrt(mse))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easier metric to understand is the mean absolute error, this means that on average our prediction was 7.6 away from the true prediction. Mean squared error, and consequently root mean squared error (RMSE), results in predictions further and further from the true value are punished more.\n",
    "\n",
    "We can calculate the same on the test data to understand how we the model is generalised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613     156\n",
      "524     240\n",
      "690     170\n",
      "457     140\n",
      "85     1042\n",
      "       ... \n",
      "279     434\n",
      "196     350\n",
      "246     402\n",
      "221     478\n",
      "239     384\n",
      "Name: gross_runtime, Length: 180, dtype: int64 [-126.15658139  513.35436477  -30.3607599   123.30085896 1080.55123964\n",
      "  820.09218981 1005.56191358   14.43948408   18.81038806 1220.48273594\n",
      "  -23.25459531  198.68901773 -451.0021805   -98.64275408 -143.04416535\n",
      "   66.68471953  706.19566568  906.48195806  109.5707364   984.75541815\n",
      "  343.65598718  762.81180511  485.84053746 -355.20635902 -180.73824473\n",
      " 1205.11054637  263.89692442  381.35006656  485.84053746 -295.85495898\n",
      "  810.68613658  -68.05483929  852.75111995 -317.51227963 -102.19262455\n",
      "  933.33121621  109.5707364  1215.29079845  967.86783419   31.02511623\n",
      "  -60.94867469  393.56479473 1217.32527454 1008.71937498  188.50876565\n",
      "  640.98775899 1177.59671907  -30.3607599   815.05704056  448.14645808\n",
      "  506.24820017  735.29797781 1156.78638067  735.29797781  366.97347836\n",
      " -337.91994234 -317.51227963 1193.63347779  646.17969648  396.72225614\n",
      "  875.89404327 -258.16087959 1278.45356705 -375.61402173  355.87071535\n",
      "  301.59100381  793.39971991 1280.49870514  318.17663596  305.96190779\n",
      "   14.43948408 -279.81820025  551.04844415  -68.05483929  219.09668044\n",
      "  226.20284504  971.0252956   359.02817675  892.47967542  410.45237869\n",
      " 1258.17681533 1280.49870514  361.73081257 1258.17681533  393.56479473\n",
      " -163.85066077  800.5058845  1205.11054637  603.2936796  1139.90263968\n",
      " -337.91994234  581.63635895 -102.19262455   66.68471953 1177.59671907\n",
      " 1049.27287843 1242.80462576   31.02511623  735.29797781  652.13867269\n",
      " 1295.87089472 1278.45356705  810.68613658  -60.94867469  475.66028538\n",
      " 1280.49870514 1193.63347779  721.56785525 1242.80462576  762.81180511\n",
      "  652.13867269 -203.3569103  1529.95614549  513.35436477  810.68613658\n",
      "  198.68901773  890.44519934 -163.85066077 1125.35148362  971.0252956\n",
      "  131.89262622    7.33331948 1295.87089472  144.10735439 1217.32527454\n",
      " 1412.50300335 -451.0021805   485.84053746 -413.30810112  831.09379929\n",
      " 1255.01935392  640.98775899  332.1789186    18.81038806 -139.88670394\n",
      " 1118.24531902  294.48483921 1118.24531902 1412.50300335 1205.11054637\n",
      "  131.89262622 -177.58078333   66.68471953  646.17969648 -139.88670394\n",
      "  605.32815569 -220.4668002   868.78787868 -218.43232412  527.90552083\n",
      "   71.87665702 -355.20635902  419.04414595 1022.44949754 1374.80892396\n",
      "   45.02739887  475.66028538   81.80828403 1295.87089472  -23.25459531\n",
      "  643.02223508  937.30386702  588.74252354 1022.44949754  772.99205719\n",
      "  605.32815569 -177.58078333 -256.1264035   838.19996389  236.38309712\n",
      "  305.96190779  506.24820017  668.50158629 -279.81820025  630.80750691\n",
      "  892.47967542  933.33121621  868.78787868 1087.65740423  793.39971991]\n",
      "mse =  375979.54494937614  & mae =  398.6734667726486  & rmse =  613.1717091886874\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_scaled)\n",
    "test_mse = mean_squared_error(y_test, predictions)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(y_test, predictions)\n",
    "print(\"mse = \",test_mse,\" & mae = \",test_mae,\" & rmse = \", sqrt(test_mse))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are actually seeing better results on our test data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Parameters\n",
    "\n",
    "More information on Generalized Linear Models can be found in the scikit-learn documentation [here](http://scikit-learn.org/stable/modules/linear_model.html)\n",
    "\n",
    "There are a number of parameters that can be tuned that should be explored when trying to improve Linear Regression models. A common approach is to test many different parameters, building multiple models and testing their accuracy to find the best combination.\n",
    "\n",
    "### Parameters\n",
    "For Linear Regression, the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) provides parameters that can be passed by the user; changing these are likely to have an impact on the performance of the model. \n",
    "\n",
    "Here is high-level information on the parameters, the documentation has more details:\n",
    "- fit_intercept : default True\n",
    "    - whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations (e.g. data is expected to be already centered).\n",
    "\n",
    "- normalize : default False\n",
    "    - This parameter is ignored when fit_intercept is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use sklearn.preprocessing.StandardScaler before calling fit on an estimator with normalize=False.\n",
    "\n",
    "- copy_X : default True\n",
    "    - If True, X will be copied; else, it may be overwritten.\n",
    "\n",
    "- n_jobs : default 1\n",
    "    - The number of jobs to use for the computation. If -1 all CPUs are used. This will only provide speedup for n_targets > 1 and sufficient large problems.\n",
    "\n",
    "### Grid Search\n",
    "\n",
    "To search for the best hyper-parameters for your algorithm and data, grid search cross validation is commonly used. The [scikit-learn documentation](http://scikit-learn.org/stable/modules/grid_search.html) provides more thorough information on how to use this. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Citation\n",
    "\n",
    "Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
