{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_count</th>\n",
       "      <th>machine_type</th>\n",
       "      <th>slots</th>\n",
       "      <th>memory</th>\n",
       "      <th>data_size_MB</th>\n",
       "      <th>features</th>\n",
       "      <th>observations</th>\n",
       "      <th>k</th>\n",
       "      <th>gross_runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>m4.2xlarge</td>\n",
       "      <td>16</td>\n",
       "      <td>64000</td>\n",
       "      <td>8000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>12</td>\n",
       "      <td>r4.xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>366000</td>\n",
       "      <td>16000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>12</td>\n",
       "      <td>r4.xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>366000</td>\n",
       "      <td>16000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>12</td>\n",
       "      <td>r4.xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>366000</td>\n",
       "      <td>16000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>12</td>\n",
       "      <td>r4.xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>366000</td>\n",
       "      <td>16000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>12</td>\n",
       "      <td>r4.xlarge</td>\n",
       "      <td>48</td>\n",
       "      <td>366000</td>\n",
       "      <td>16000</td>\n",
       "      <td>5</td>\n",
       "      <td>150000000</td>\n",
       "      <td>3</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instance_count machine_type  slots  memory  data_size_MB  features  \\\n",
       "0                 2   m4.2xlarge     16   64000          8000         5   \n",
       "1                 2   m4.2xlarge     16   64000          8000         5   \n",
       "2                 2   m4.2xlarge     16   64000          8000         5   \n",
       "3                 2   m4.2xlarge     16   64000          8000         5   \n",
       "4                 2   m4.2xlarge     16   64000          8000         5   \n",
       "..              ...          ...    ...     ...           ...       ...   \n",
       "895              12    r4.xlarge     48  366000         16000         5   \n",
       "896              12    r4.xlarge     48  366000         16000         5   \n",
       "897              12    r4.xlarge     48  366000         16000         5   \n",
       "898              12    r4.xlarge     48  366000         16000         5   \n",
       "899              12    r4.xlarge     48  366000         16000         5   \n",
       "\n",
       "     observations  k  gross_runtime  \n",
       "0       150000000  3           1126  \n",
       "1       150000000  3           1127  \n",
       "2       150000000  3           1151  \n",
       "3       150000000  3           1156  \n",
       "4       150000000  3           1216  \n",
       "..            ... ..            ...  \n",
       "895     150000000  3            228  \n",
       "896     150000000  3            230  \n",
       "897     150000000  3            232  \n",
       "898     150000000  3            234  \n",
       "899     150000000  3            236  \n",
       "\n",
       "[900 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing naumpy and pandas libraries to read the data\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the numpy and pandas package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read the given CSV file, and view some sample records\n",
    "df = pd.read_csv(\"../c3o-experiments-main/kmeans.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"machine_type\" ], axis=1)\n",
    "\n",
    "dataset = df.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[        2        16     64000 ...         5 150000000         3]\n",
      " [        2        16     64000 ...         5 150000000         3]\n",
      " [        2        16     64000 ...         5 150000000         3]\n",
      " ...\n",
      " [       12        48    366000 ...         5 150000000         3]\n",
      " [       12        48    366000 ...         5 150000000         3]\n",
      " [       12        48    366000 ...         5 150000000         3]] [1126 1127 1151 1156 1216  608  608  610  610  614  770  774  774  778\n",
      "  782 1246 1246 2902 3008 3152 1186 1196 2680 2864 2970  788  794  798\n",
      "  800  804  958  960  964  972  974 1160 1170 2780 2794 2794 1112 1132\n",
      " 2710 2714 2718  920  930  930  934  934 1136 1138 1140 1142 1146  844\n",
      "  856  857 1162 1166  806  806 1124 1126 1130 1724 1750 1752 1760 1780\n",
      " 2676 2686 2689 4390 4520  848  850  860 4204 4556  806  808  816 4126\n",
      " 4274 1042 1044 1046 1050 1052 1078 1082 1086 1086 1098 1046 1068 1246\n",
      " 1260 1264  998 1008 1188 1198 1206 3116 3118 3234 3240 3284 2818 2868\n",
      " 4298 4310 4490 2900 2982 4248 4254 4258 2758 2966 4028 4216 4280 1712\n",
      " 1716 1722 1722 1724 2650 2666 2670 2674 2686 1046 1046 1050 2792 2792\n",
      " 1004 1006 1020 2714 2740 3878 3894 3916 3930 3952  436  446  454  568\n",
      "  598  246  246  248  250  252  300  304  304  306  308  298  300  304\n",
      "  312  320  312  322  326  330  330  304  306  308  314  316  354  356\n",
      "  356  362  368  368  372  372  374  376  378  382  384  388  388  348\n",
      "  350  350  354  354  418  420  422  422  434  436  438  440  446  450\n",
      "  458  458  460  462  468  382  386  388  390  394  476  478  478  478\n",
      "  480  490  490  492  496  502  508  510  510  518  524  380  382  382\n",
      "  384  384  390  392  392  392  394  394  402  404  404  406  410  410\n",
      "  412  412  416  480  484  486  486  492  554  556  556  564  566  574\n",
      "  576  580  584  592  604  604  606  610  616  426  426  426  432  434\n",
      "  498  500  502  502  502  510  510  512  514  518  526  528  528  530\n",
      "  532 1080 1082 1104 1118 1122  236  238  240  242  244  164  166  168\n",
      "  168  170  204  204  206  210  210  210  212  214  216  216  218  224\n",
      "  224  226  230  202  202  202  206  206  236  242  242  242  244  242\n",
      "  246  250  250  256  254  258  258  258  260  226  228  232  232  232\n",
      "  270  274  280  284  288  282  284  286  286  298  296  296  296  298\n",
      "  300  242  242  242  246  246  300  300  304  306  306  310  312  314\n",
      "  314  314  320  320  324  326  326  246  248  248  248  252  252  254\n",
      "  256  258  260  264  264  264  266  266  270  272  272  274  274  306\n",
      "  306  308  308  316  346  346  348  358  360  364  370  370  372  382\n",
      "  380  382  388  392  394  262  264  264  266  268  310  310  312  314\n",
      "  314  320  322  322  322  324  330  332  332  332  334  472  478  484\n",
      "  484  488  194  194  196  198  198  136  138  140  142  144  168  168\n",
      "  168  174  176  170  178  178  184  184  184  188  188  188  188  152\n",
      "  154  154  154  154  176  178  178  180  182  182  186  186  188  188\n",
      "  190  190  192  196  196  180  182  184  184  184  212  218  218  222\n",
      "  224  224  226  228  238  238  230  232  232  234  240  192  192  192\n",
      "  192  192  230  234  234  238  240  242  242  244  244  244  242  250\n",
      "  252  252  252  186  186  188  188  190  190  190  190  192  192  198\n",
      "  198  198  198  198  202  204  204  204  206  232  232  234  234  236\n",
      "  262  265  266  268  268  276  276  278  278  280  286  286  290  290\n",
      "  296  202  204  206  206  206  242  242  246  246  246  248  250  252\n",
      "  252  254  256  258  258  260  262  338  340  342  342  346  150  152\n",
      "  154  154  156  120  122  124  126  134  148  150  150  156  160  148\n",
      "  152  156  162  164  162  162  164  168  172  142  144  144  144  150\n",
      "  168  172  174  176  178  174  178  178  178  180  182  186  188  192\n",
      "  196  148  148  150  150  150  174  174  174  176  176  180  180  182\n",
      "  184  184  190  190  190  192  194  162  162  164  164  166  196  196\n",
      "  198  200  206  204  204  204  208  212  212  214  214  214  216  170\n",
      "  174  176  176  176  170  170  176  180  182  170  174  176  178  178\n",
      "  184  186  192  192  194  200  204  206  208  208  224  226  234  238\n",
      "  238  226  236  238  248  248  244  246  256  256  256  172  174  174\n",
      "  176  176  204  204  204  206  206  206  210  212  214  214  216  216\n",
      "  216  218  218  246  248  250  250  252  148  150  150  150  150   94\n",
      "   94   96   96   98  112  114  114  114  116  118  118  118  118  120\n",
      "  118  118  120  122  122  130  132  134  134  136  148  154  154  158\n",
      "  160  158  158  162  164  172  164  166  166  172  176  138  140  140\n",
      "  142  142  166  170  170  170  172  168  170  174  174  180  180  184\n",
      "  186  188  194  142  142  142  142  144  172  172  172  174  176  176\n",
      "  176  180  180  182  182  182  182  184  186  140  140  140  140  140\n",
      "  142  142  144  146  146  146  146  148  148  152  150  152  152  154\n",
      "  154  160  160  162  162  164  180  182  184  186  186  188  188  190\n",
      "  190  194  196  196  198  200  202  144  144  144  146  146  168  170\n",
      "  170  170  174  172  174  174  178  178  180  180  180  180  182  228\n",
      "  230  232  234  236]\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,0:7]\n",
    "\n",
    "Y = dataset[:,-1]\n",
    "\n",
    "print(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.09090909, 0.00447094, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [0.        , 0.09090909, 0.00447094, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [0.        , 0.09090909, 0.00447094, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.45454545, 0.45454545, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [1.        , 0.45454545, 0.45454545, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [1.        , 0.45454545, 0.45454545, ..., 0.        , 0.5       ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(7,)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='mae',\n",
    "              metrics=['sparse_categorical_crossentropy '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 650, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 204, in get\n        return deserialize(str(identifier))\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 158, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py\", line 543, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: 'sparse_categorical_crossentropy '. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\serap\\Desktop\\Data Synthesizer\\Model\\nn.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/serap/Desktop/Data%20Synthesizer/Model/nn.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/serap/Desktop/Data%20Synthesizer/Model/nn.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file0am0jiun.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 650, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 204, in get\n        return deserialize(str(identifier))\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 158, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\serap\\anaconda3\\envs\\CBeIntelli_3_8\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py\", line 543, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: 'sparse_categorical_crossentropy '. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 5ms/step\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999947 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.999979  ]\n",
      " [0.9999675 ]\n",
      " [0.9999999 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999995 ]\n",
      " [0.99998826]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998635]\n",
      " [0.9999995 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.999979  ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999998 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999996 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.999979  ]\n",
      " [0.99999803]\n",
      " [0.9999999 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999984 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999803]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998635]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999675 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999965 ]\n",
      " [0.99999976]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999984 ]\n",
      " [0.9999995 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999947 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999994 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998313]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999999 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999957 ]\n",
      " [0.99999976]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998635]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999998 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999934 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999947 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99998313]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999998 ]\n",
      " [0.9999999 ]\n",
      " [0.99998826]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999987 ]\n",
      " [1.        ]\n",
      " [0.99999976]\n",
      " [0.9999998 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999999 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999803]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]] [ 162  332  266  382  342 2670  298  958  610  258  144  150  492  190\n",
      "  184  170  204  206  608 1127 4258  178  232  226  314  244  228  234\n",
      "  432 2792  206  604  184  252  446  472 2689 3878  150  180  254  140\n",
      "  242  174  206  168  150  226  234   96  202  426  242  144  426 3008\n",
      " 2676  420  374  608  148  320 1082  176  354 4204  384  188  174  232\n",
      "  610  930 1260  286  262 1140  616  230  246  300  170  934  196  346\n",
      "  266  228  150  236 1050 1246  168  264  142  160 1151  186  384  194\n",
      "  202  394  114  186  320  468  164  300  498  178  176  118  426  310\n",
      "  314  332 2714 1044  210  206  190  146  346  322  280  262  192  152\n",
      "  492  192  382  154  248  124 1138 4390  192  246  114  960  412  252\n",
      "  180  198  272 1780  146  174  212  142  248  308  774  416  146  178\n",
      "  486  268   94  242  166  218  150  154 2674  192  256  256  312  436\n",
      "  202  260 4028  388  246  176 2780 1052  528  206  208 2902  148  230\n",
      " 1098  218  168  208  204  234 1046  160  116  174  260  174  462  212\n",
      "  186  510  370  382  368  376  186  254  230  566  150  788  192  120\n",
      "  204  204  202  964  246  204  310  568  306  434  774  298  158  186\n",
      "  180  224  500  350  122  300  162  264  148  194  252 3118 1082 3952\n",
      "  510  574  206  844  224 1046 3116  190  268 1198  180  232  174  174\n",
      "  510 2714  256  190  144  180 1716  320  920  236  200  234  210  204\n",
      "  418  164  202  146]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test), Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CBeIntelli_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
